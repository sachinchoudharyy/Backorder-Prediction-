{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of the dataset:\n",
      "       sku  national_inv  lead_time  in_transit_qty  forecast_3_month  \\\n",
      "0  1113121             0        8.0               1                 6   \n",
      "1  1113268             0        8.0               0                 2   \n",
      "2  1113874            20        2.0               0                45   \n",
      "3  1114222             0        8.0               0                 9   \n",
      "4  1114823             0       12.0               0                31   \n",
      "\n",
      "   forecast_6_month  forecast_9_month  sales_1_month  sales_3_month  \\\n",
      "0                 6                 6              0              4   \n",
      "1                 3                 4              1              2   \n",
      "2                99               153             16             42   \n",
      "3                14                21              5             17   \n",
      "4                31                31              7             15   \n",
      "\n",
      "   sales_6_month  ...  pieces_past_due  perf_6_month_avg perf_12_month_avg  \\\n",
      "0              9  ...                1              0.90              0.89   \n",
      "1              3  ...                0              0.96              0.97   \n",
      "2             80  ...                0              0.81              0.88   \n",
      "3             36  ...                0              0.96              0.98   \n",
      "4             33  ...                3              0.98              0.98   \n",
      "\n",
      "   local_bo_qty  deck_risk  oe_constraint  ppap_risk stop_auto_buy rev_stop  \\\n",
      "0             0         No             No         No           Yes       No   \n",
      "1             0         No             No         No           Yes       No   \n",
      "2             0         No             No         No           Yes       No   \n",
      "3             0         No             No         No           Yes       No   \n",
      "4             0         No             No         No           Yes       No   \n",
      "\n",
      "  went_on_backorder  \n",
      "0               Yes  \n",
      "1               Yes  \n",
      "2               Yes  \n",
      "3               Yes  \n",
      "4               Yes  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "\n",
      "Dataset Summary:\n",
      "                sku   national_inv     lead_time  in_transit_qty  \\\n",
      "count  1.905300e+04   19053.000000  17975.000000    19053.000000   \n",
      "mean   2.059553e+06     376.367029      7.706036       48.272346   \n",
      "std    6.633376e+05    7002.071629      6.778665     1465.999210   \n",
      "min    1.111620e+06   -1440.000000      0.000000        0.000000   \n",
      "25%    1.510598e+06       3.000000      4.000000        0.000000   \n",
      "50%    1.923192e+06      11.000000      8.000000        0.000000   \n",
      "75%    2.828574e+06      63.000000      8.000000        0.000000   \n",
      "max    3.284775e+06  730722.000000     52.000000   170920.000000   \n",
      "\n",
      "       forecast_3_month  forecast_6_month  forecast_9_month  sales_1_month  \\\n",
      "count      19053.000000      19053.000000      1.905300e+04   19053.000000   \n",
      "mean         182.910828        344.739831      4.977924e+02      56.118879   \n",
      "std         4304.865592       8406.062155      1.218057e+04    1544.217778   \n",
      "min            0.000000          0.000000      0.000000e+00       0.000000   \n",
      "25%            0.000000          0.000000      0.000000e+00       0.000000   \n",
      "50%            0.000000          0.000000      0.000000e+00       0.000000   \n",
      "75%            9.000000         20.000000      3.000000e+01       5.000000   \n",
      "max       479808.000000     967776.000000      1.418208e+06  186451.000000   \n",
      "\n",
      "       sales_3_month  sales_6_month  sales_9_month      min_bank  \\\n",
      "count   19053.000000   1.905300e+04   1.905300e+04  19053.000000   \n",
      "mean      168.534457   3.335322e+02   5.042554e+02     48.840708   \n",
      "std      4581.340080   9.294566e+03   1.418415e+04    968.773868   \n",
      "min         0.000000   0.000000e+00   0.000000e+00      0.000000   \n",
      "25%         0.000000   0.000000e+00   0.000000e+00      0.000000   \n",
      "50%         1.000000   3.000000e+00   5.000000e+00      0.000000   \n",
      "75%        16.000000   3.200000e+01   4.700000e+01      3.000000   \n",
      "max    550609.000000   1.136154e+06   1.759152e+06  85584.000000   \n",
      "\n",
      "       pieces_past_due  perf_6_month_avg  perf_12_month_avg  local_bo_qty  \n",
      "count      19053.00000      19053.000000       19053.000000  19053.000000  \n",
      "mean           2.31150         -6.519834          -6.053935      0.891776  \n",
      "std          110.24106         25.975139          25.184497     23.033345  \n",
      "min            0.00000        -99.000000         -99.000000      0.000000  \n",
      "25%            0.00000          0.630000           0.650000      0.000000  \n",
      "50%            0.00000          0.820000           0.800000      0.000000  \n",
      "75%            0.00000          0.960000           0.950000      0.000000  \n",
      "max        13824.00000          1.000000           1.000000   1440.000000  \n",
      "\n",
      "Data Types and Missing Values:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19053 entries, 0 to 19052\n",
      "Data columns (total 23 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   sku                19053 non-null  int64  \n",
      " 1   national_inv       19053 non-null  int64  \n",
      " 2   lead_time          17975 non-null  float64\n",
      " 3   in_transit_qty     19053 non-null  int64  \n",
      " 4   forecast_3_month   19053 non-null  int64  \n",
      " 5   forecast_6_month   19053 non-null  int64  \n",
      " 6   forecast_9_month   19053 non-null  int64  \n",
      " 7   sales_1_month      19053 non-null  int64  \n",
      " 8   sales_3_month      19053 non-null  int64  \n",
      " 9   sales_6_month      19053 non-null  int64  \n",
      " 10  sales_9_month      19053 non-null  int64  \n",
      " 11  min_bank           19053 non-null  int64  \n",
      " 12  potential_issue    19053 non-null  object \n",
      " 13  pieces_past_due    19053 non-null  int64  \n",
      " 14  perf_6_month_avg   19053 non-null  float64\n",
      " 15  perf_12_month_avg  19053 non-null  float64\n",
      " 16  local_bo_qty       19053 non-null  int64  \n",
      " 17  deck_risk          19053 non-null  object \n",
      " 18  oe_constraint      19053 non-null  object \n",
      " 19  ppap_risk          19053 non-null  object \n",
      " 20  stop_auto_buy      19053 non-null  object \n",
      " 21  rev_stop           19053 non-null  object \n",
      " 22  went_on_backorder  19053 non-null  object \n",
      "dtypes: float64(3), int64(13), object(7)\n",
      "memory usage: 3.3+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('Products.csv')\n",
    "\n",
    "# Show the first 5 rows of the dataset\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "print(df.head())\n",
    "\n",
    "# Summary of the dataset\n",
    "print(\"\\nDataset Summary:\")\n",
    "print(df.describe())\n",
    "\n",
    "# Checking the data types and missing values\n",
    "print(\"\\nData Types and Missing Values:\")\n",
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values in each column:\n",
      "sku                     0\n",
      "national_inv            0\n",
      "lead_time            1078\n",
      "in_transit_qty          0\n",
      "forecast_3_month        0\n",
      "forecast_6_month        0\n",
      "forecast_9_month        0\n",
      "sales_1_month           0\n",
      "sales_3_month           0\n",
      "sales_6_month           0\n",
      "sales_9_month           0\n",
      "min_bank                0\n",
      "potential_issue         0\n",
      "pieces_past_due         0\n",
      "perf_6_month_avg        0\n",
      "perf_12_month_avg       0\n",
      "local_bo_qty            0\n",
      "deck_risk               0\n",
      "oe_constraint           0\n",
      "ppap_risk               0\n",
      "stop_auto_buy           0\n",
      "rev_stop                0\n",
      "went_on_backorder       0\n",
      "dtype: int64\n",
      "\n",
      "Cleaned Data:\n",
      "       sku  national_inv  lead_time  in_transit_qty  forecast_3_month  \\\n",
      "0  1113121             0        8.0               1                 6   \n",
      "1  1113268             0        8.0               0                 2   \n",
      "2  1113874            20        2.0               0                45   \n",
      "3  1114222             0        8.0               0                 9   \n",
      "4  1114823             0       12.0               0                31   \n",
      "\n",
      "   forecast_6_month  forecast_9_month  sales_1_month  sales_3_month  \\\n",
      "0                 6                 6              0              4   \n",
      "1                 3                 4              1              2   \n",
      "2                99               153             16             42   \n",
      "3                14                21              5             17   \n",
      "4                31                31              7             15   \n",
      "\n",
      "   sales_6_month  ...  pieces_past_due  perf_6_month_avg  perf_12_month_avg  \\\n",
      "0              9  ...                1              0.90               0.89   \n",
      "1              3  ...                0              0.96               0.97   \n",
      "2             80  ...                0              0.81               0.88   \n",
      "3             36  ...                0              0.96               0.98   \n",
      "4             33  ...                3              0.98               0.98   \n",
      "\n",
      "   local_bo_qty  deck_risk  oe_constraint  ppap_risk  stop_auto_buy  rev_stop  \\\n",
      "0             0          0              0          0              1         0   \n",
      "1             0          0              0          0              1         0   \n",
      "2             0          0              0          0              1         0   \n",
      "3             0          0              0          0              1         0   \n",
      "4             0          0              0          0              1         0   \n",
      "\n",
      "   went_on_backorder  \n",
      "0                  1  \n",
      "1                  1  \n",
      "2                  1  \n",
      "3                  1  \n",
      "4                  1  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SACHIN\\AppData\\Local\\Temp\\ipykernel_6928\\1981165814.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned['went_on_backorder'] = df_cleaned['went_on_backorder'].map({'Yes': 1, 'No': 0})\n",
      "C:\\Users\\SACHIN\\AppData\\Local\\Temp\\ipykernel_6928\\1981165814.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned['potential_issue'] = df_cleaned['potential_issue'].map({'Yes': 1, 'No': 0})\n",
      "C:\\Users\\SACHIN\\AppData\\Local\\Temp\\ipykernel_6928\\1981165814.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned['deck_risk'] = df_cleaned['deck_risk'].map({'Yes': 1, 'No': 0})\n",
      "C:\\Users\\SACHIN\\AppData\\Local\\Temp\\ipykernel_6928\\1981165814.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned['oe_constraint'] = df_cleaned['oe_constraint'].map({'Yes': 1, 'No': 0})\n",
      "C:\\Users\\SACHIN\\AppData\\Local\\Temp\\ipykernel_6928\\1981165814.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned['ppap_risk'] = df_cleaned['ppap_risk'].map({'Yes': 1, 'No': 0})\n",
      "C:\\Users\\SACHIN\\AppData\\Local\\Temp\\ipykernel_6928\\1981165814.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned['stop_auto_buy'] = df_cleaned['stop_auto_buy'].map({'Yes': 1, 'No': 0})\n",
      "C:\\Users\\SACHIN\\AppData\\Local\\Temp\\ipykernel_6928\\1981165814.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned['rev_stop'] = df_cleaned['rev_stop'].map({'Yes': 1, 'No': 0})\n"
     ]
    }
   ],
   "source": [
    "# Checking for missing values\n",
    "print(\"\\nMissing values in each column:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Dropping missing values (if applicable)\n",
    "df_cleaned = df.dropna()\n",
    "\n",
    "# Handling categorical features by converting 'Yes'/'No' to binary values (0 and 1)\n",
    "df_cleaned['went_on_backorder'] = df_cleaned['went_on_backorder'].map({'Yes': 1, 'No': 0})\n",
    "df_cleaned['potential_issue'] = df_cleaned['potential_issue'].map({'Yes': 1, 'No': 0})\n",
    "df_cleaned['deck_risk'] = df_cleaned['deck_risk'].map({'Yes': 1, 'No': 0})\n",
    "df_cleaned['oe_constraint'] = df_cleaned['oe_constraint'].map({'Yes': 1, 'No': 0})\n",
    "df_cleaned['ppap_risk'] = df_cleaned['ppap_risk'].map({'Yes': 1, 'No': 0})\n",
    "df_cleaned['stop_auto_buy'] = df_cleaned['stop_auto_buy'].map({'Yes': 1, 'No': 0})\n",
    "df_cleaned['rev_stop'] = df_cleaned['rev_stop'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "print(\"\\nCleaned Data:\")\n",
    "print(df_cleaned.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected Features:\n",
      "Index(['national_inv', 'lead_time', 'in_transit_qty', 'forecast_3_month',\n",
      "       'forecast_6_month', 'forecast_9_month', 'sales_1_month',\n",
      "       'sales_3_month', 'sales_6_month', 'sales_9_month', 'min_bank',\n",
      "       'potential_issue', 'pieces_past_due', 'perf_6_month_avg',\n",
      "       'perf_12_month_avg', 'local_bo_qty', 'deck_risk', 'oe_constraint',\n",
      "       'ppap_risk', 'stop_auto_buy', 'rev_stop'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Defining features and target variable\n",
    "X = df_cleaned.drop(columns=['sku', 'went_on_backorder'])  # Removing 'sku' and 'went_on_backorder' from features\n",
    "y = df_cleaned['went_on_backorder']\n",
    "\n",
    "print(\"\\nSelected Features:\")\n",
    "print(X.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training and Testing Data Shapes:\n",
      "X_train: (14380, 21), X_test: (3595, 21)\n",
      "y_train: (14380,), y_test: (3595,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Splitting the data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"\\nTraining and Testing Data Shapes:\")\n",
    "print(f\"X_train: {X_train.shape}, X_test: {X_test.shape}\")\n",
    "print(f\"y_train: {y_train.shape}, y_test: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Training Complete\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Training the model using RandomForestClassifier\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nModel Training Complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Accuracy: 0.93\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3063   99]\n",
      " [ 161  272]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      3162\n",
      "           1       0.73      0.63      0.68       433\n",
      "\n",
      "    accuracy                           0.93      3595\n",
      "   macro avg       0.84      0.80      0.82      3595\n",
      "weighted avg       0.92      0.93      0.93      3595\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Predicting the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluating the model performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nModel Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Confusion matrix and classification report\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n",
      "\n",
      "Best Parameters: {'max_depth': 20, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "\n",
      "Tuned Model Accuracy: 0.92\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Defining the parameter grid for tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Performing grid search with cross-validation\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters from the grid search\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"\\nBest Parameters: {best_params}\")\n",
    "\n",
    "# Model with best parameters\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Re-evaluate the tuned model\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "accuracy_best = accuracy_score(y_test, y_pred_best)\n",
    "print(f\"\\nTuned Model Accuracy: {accuracy_best:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
